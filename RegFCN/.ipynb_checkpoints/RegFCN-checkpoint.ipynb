{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load TensorflowUitls.py\n",
    "__author__ = 'Charlie'\n",
    "# Utils used with tensorflow implemetation\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    "import os, sys\n",
    "from six.moves import urllib\n",
    "import tarfile\n",
    "import zipfile\n",
    "import scipy.io\n",
    " \n",
    "\n",
    "# 获取VGG预训练模型\n",
    "def get_model_data(dir_path, model_url):\n",
    "    # model_dir Model_zoo/\n",
    "    # MODEL_URL 下载VGG19网址\n",
    "    maybe_download_and_extract(dir_path, model_url)     # 判断文件目录和文件是否存在， 不存在则下载\n",
    "    filename = model_url.split(\"/\")[-1]                 # 将url按/切分， 取最后一个字符串作为文件名\n",
    "    filepath = os.path.join(dir_path, filename)         # dir_path/filename     文件全路径\n",
    "    if not os.path.exists(filepath):                    # 判断是否存在此文件\n",
    "        raise IOError(\"VGG Model not found!\")\n",
    "    data = scipy.io.loadmat(filepath)                   # 使用io读取VGG.mat文件\n",
    "    return data\n",
    " \n",
    "\n",
    "    \n",
    "def maybe_download_and_extract(dir_path, url_name, is_tarfile=False, is_zipfile=False):\n",
    "    # dir_path Model_zoo/\n",
    "    # url_name 下载VGG19网址\n",
    "    if not os.path.exists(dir_path):        # 判断文件路径是否存在，如果不存在则创建此路径\n",
    "        os.makedirs(dir_path)\n",
    "    filename = url_name.split('/')[-1]      # 将url中 按照/切分，并取最后一个字符串 作为文件名字\n",
    "    filepath = os.path.join(dir_path, filename)     # 文件路径 = dir_path/filename\n",
    "    if not os.path.exists(filepath):         # 判断此路径是否存在（此文件），如果不存在，则下载\n",
    "        def _progress(count, block_size, total_size):       # 内部函数\n",
    "            sys.stdout.write(\n",
    "                '\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "            sys.stdout.flush()\n",
    " \n",
    "        filepath, _ = urllib.request.urlretrieve(url_name, filepath, reporthook=_progress)    # 将url中文件 下载到filepath路径中\n",
    "        print()\n",
    "        statinfo = os.stat(filepath)\n",
    "        print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "        if is_tarfile:          # 如果是tar文件， 解压缩\n",
    "            tarfile.open(filepath, 'r:gz').extractall(dir_path)\n",
    "        elif is_zipfile:        # 如果是zip文件 解压缩\n",
    "            with zipfile.ZipFile(filepath) as zf:\n",
    "                zip_dir = zf.namelist()[0]\n",
    "                zf.extractall(dir_path)\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "def save_image(image, save_dir, name, mean=None):\n",
    "    \"\"\"\n",
    "    Save image by unprocessing if mean given else just save\n",
    "    :param mean:\n",
    "    :param image:\n",
    "    :param save_dir:\n",
    "    :param name:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if mean:\n",
    "        image = unprocess_image(image, mean)\n",
    "    misc.imsave(os.path.join(save_dir, name + \".png\"), image)\n",
    "\n",
    "\n",
    "def get_variable(weights, name):\n",
    "    init = tf.constant_initializer(weights, dtype=tf.float32)\n",
    "    var = tf.get_variable(name=name, initializer=init,  shape=weights.shape)\n",
    "    return var\n",
    "\n",
    "\n",
    "def weight_variable(shape, stddev=0.02, name=None):\n",
    "    # print(shape)\n",
    "    initial = tf.truncated_normal(shape, stddev=stddev)\n",
    "    if name is None:\n",
    "        return tf.Variable(initial)\n",
    "    else:\n",
    "        return tf.get_variable(name, initializer=initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape, name=None):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    if name is None:\n",
    "        return tf.Variable(initial)\n",
    "    else:\n",
    "        return tf.get_variable(name, initializer=initial)\n",
    "\n",
    "\n",
    "def get_tensor_size(tensor):\n",
    "    from operator import mul\n",
    "    return reduce(mul, (d.value for d in tensor.get_shape()), 1)\n",
    "\n",
    "\n",
    "def conv2d_basic(x, W, bias):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding=\"SAME\")\n",
    "    return tf.nn.bias_add(conv, bias)\n",
    "\n",
    "\n",
    "def conv2d_strided(x, W, b):\n",
    "    conv = tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "    return tf.nn.bias_add(conv, b)\n",
    "\n",
    "\n",
    "def conv2d_transpose_strided(x, W, b, output_shape=None, stride = 2):\n",
    "    # print x.get_shape()\n",
    "    # print W.get_shape()\n",
    "    if output_shape is None:\n",
    "        output_shape = x.get_shape().as_list()\n",
    "        output_shape[1] *= 2\n",
    "        output_shape[2] *= 2\n",
    "        output_shape[3] = W.get_shape().as_list()[2]\n",
    "    # print output_shape\n",
    "    conv = tf.nn.conv2d_transpose(x, W, output_shape, strides=[1, stride, stride, 1], padding=\"SAME\")\n",
    "    return tf.nn.bias_add(conv, b)\n",
    "\n",
    "\n",
    "def leaky_relu(x, alpha=0.0, name=\"\"):\n",
    "    return tf.maximum(alpha * x, x, name)\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def avg_pool_2x2(x):\n",
    "    return tf.nn.avg_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"SAME\")\n",
    "\n",
    "\n",
    "def local_response_norm(x):\n",
    "    return tf.nn.lrn(x, depth_radius=5, bias=2, alpha=1e-4, beta=0.75)\n",
    "\n",
    "\n",
    "def batch_norm(x, n_out, phase_train, scope='bn', decay=0.9, eps=1e-5):\n",
    "    \"\"\"\n",
    "    Code taken from http://stackoverflow.com/a/34634291/2267819\n",
    "    \"\"\"\n",
    "    with tf.variable_scope(scope):\n",
    "        beta = tf.get_variable(name='beta', shape=[n_out], initializer=tf.constant_initializer(0.0)\n",
    "                               , trainable=True)\n",
    "        gamma = tf.get_variable(name='gamma', shape=[n_out], initializer=tf.random_normal_initializer(1.0, 0.02),\n",
    "                                trainable=True)\n",
    "        batch_mean, batch_var = tf.nn.moments(x, [0, 1, 2], name='moments')\n",
    "        ema = tf.train.ExponentialMovingAverage(decay=decay)\n",
    "\n",
    "        def mean_var_with_update():\n",
    "            ema_apply_op = ema.apply([batch_mean, batch_var])\n",
    "            with tf.control_dependencies([ema_apply_op]):\n",
    "                return tf.identity(batch_mean), tf.identity(batch_var)\n",
    "\n",
    "        mean, var = tf.cond(phase_train,\n",
    "                            mean_var_with_update,\n",
    "                            lambda: (ema.average(batch_mean), ema.average(batch_var)))\n",
    "        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, eps)\n",
    "    return normed\n",
    "\n",
    "\n",
    "def process_image(image, mean_pixel):\n",
    "    return image - mean_pixel\n",
    "\n",
    "\n",
    "def unprocess_image(image, mean_pixel):\n",
    "    return image + mean_pixel\n",
    "\n",
    "\n",
    "def bottleneck_unit(x, out_chan1, out_chan2, down_stride=False, up_stride=False, name=None):\n",
    "    \"\"\"\n",
    "    Modified implementation from github ry?!\n",
    "    \"\"\"\n",
    "\n",
    "    def conv_transpose(tensor, out_channel, shape, strides, name=None):\n",
    "        out_shape = tensor.get_shape().as_list()\n",
    "        in_channel = out_shape[-1]\n",
    "        kernel = weight_variable([shape, shape, out_channel, in_channel], name=name)\n",
    "        shape[-1] = out_channel\n",
    "        return tf.nn.conv2d_transpose(x, kernel, output_shape=out_shape, strides=[1, strides, strides, 1],\n",
    "                                      padding='SAME', name='conv_transpose')\n",
    "\n",
    "    def conv(tensor, out_chans, shape, strides, name=None):\n",
    "        in_channel = tensor.get_shape().as_list()[-1]\n",
    "        kernel = weight_variable([shape, shape, in_channel, out_chans], name=name)\n",
    "        return tf.nn.conv2d(x, kernel, strides=[1, strides, strides, 1], padding='SAME', name='conv')\n",
    "\n",
    "    def bn(tensor, name=None):\n",
    "        \"\"\"\n",
    "        :param tensor: 4D tensor input\n",
    "        :param name: name of the operation\n",
    "        :return: local response normalized tensor - not using batch normalization :(\n",
    "        \"\"\"\n",
    "        return tf.nn.lrn(tensor, depth_radius=5, bias=2, alpha=1e-4, beta=0.75, name=name)\n",
    "\n",
    "    in_chans = x.get_shape().as_list()[3]\n",
    "\n",
    "    if down_stride or up_stride:\n",
    "        first_stride = 2\n",
    "    else:\n",
    "        first_stride = 1\n",
    "\n",
    "    with tf.variable_scope('res%s' % name):\n",
    "        if in_chans == out_chan2:\n",
    "            b1 = x\n",
    "        else:\n",
    "            with tf.variable_scope('branch1'):\n",
    "                if up_stride:\n",
    "                    b1 = conv_transpose(x, out_chans=out_chan2, shape=1, strides=first_stride,\n",
    "                                        name='res%s_branch1' % name)\n",
    "                else:\n",
    "                    b1 = conv(x, out_chans=out_chan2, shape=1, strides=first_stride, name='res%s_branch1' % name)\n",
    "                b1 = bn(b1, 'bn%s_branch1' % name, 'scale%s_branch1' % name)\n",
    "\n",
    "        with tf.variable_scope('branch2a'):\n",
    "            if up_stride:\n",
    "                b2 = conv_transpose(x, out_chans=out_chan1, shape=1, strides=first_stride, name='res%s_branch2a' % name)\n",
    "            else:\n",
    "                b2 = conv(x, out_chans=out_chan1, shape=1, strides=first_stride, name='res%s_branch2a' % name)\n",
    "            b2 = bn(b2, 'bn%s_branch2a' % name, 'scale%s_branch2a' % name)\n",
    "            b2 = tf.nn.relu(b2, name='relu')\n",
    "\n",
    "        with tf.variable_scope('branch2b'):\n",
    "            b2 = conv(b2, out_chans=out_chan1, shape=3, strides=1, name='res%s_branch2b' % name)\n",
    "            b2 = bn(b2, 'bn%s_branch2b' % name, 'scale%s_branch2b' % name)\n",
    "            b2 = tf.nn.relu(b2, name='relu')\n",
    "\n",
    "        with tf.variable_scope('branch2c'):\n",
    "            b2 = conv(b2, out_chans=out_chan2, shape=1, strides=1, name='res%s_branch2c' % name)\n",
    "            b2 = bn(b2, 'bn%s_branch2c' % name, 'scale%s_branch2c' % name)\n",
    "\n",
    "        x = b1 + b2\n",
    "        return tf.nn.relu(x, name='relu')\n",
    "\n",
    "\n",
    "def add_to_regularization_and_summary(var):\n",
    "    if var is not None:\n",
    "        tf.summary.histogram(var.op.name, var)\n",
    "        tf.add_to_collection(\"reg_loss\", tf.nn.l2_loss(var))\n",
    "\n",
    "\n",
    "def add_activation_summary(var):\n",
    "    if var is not None:\n",
    "        tf.summary.histogram(var.op.name + \"/activation\", var)\n",
    "        tf.summary.scalar(var.op.name + \"/sparsity\", tf.nn.zero_fraction(var))\n",
    "\n",
    "\n",
    "def add_gradient_summary(grad, var):\n",
    "    if grad is not None:\n",
    "        tf.summary.histogram(var.op.name + \"/gradient\", grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load BatchDatsetReader.py\n",
    "\"\"\"\n",
    "Code ideas from https://github.com/Newmu/dcgan and tensorflow mnist dataset reader\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import scipy.misc as misc\n",
    " \n",
    "    \n",
    "class BatchDatset:\n",
    "    files = []\n",
    "    images = []\n",
    "    annotations = []\n",
    "    image_options = {}\n",
    "    batch_offset = 0\n",
    "    epochs_completed = 0\n",
    " \n",
    "    def __init__(self, records_list, image_options={}):\n",
    "        \"\"\"\n",
    "        Intialize a generic file reader with batching for list of files\n",
    "        :param records_list: list of file records to read -\n",
    "        sample record: {'image': f, 'annotation': annotation_file, 'filename': filename}\n",
    "        :param image_options: A dictionary of options for modifying the output image\n",
    "        Available options:\n",
    "        resize = True/ False\n",
    "        resize_size = #size of output image - does bilinear resize\n",
    "        color=True/False\n",
    "        \"\"\"\n",
    "        print(\"Initializing Batch Dataset Reader...\")\n",
    "        print(image_options)\n",
    "        self.files = records_list       # 文件列表\n",
    "        self.image_options = image_options  # 图片操作方式 resize  224\n",
    "        self._read_images()\n",
    " \n",
    "    def _read_images(self):\n",
    "        self.__channels = True\n",
    "        # 扫描files字典中所有image 图片全路径\n",
    "        # 根据文件全路径读取图像，并将其扩充为RGB格式\n",
    "        self.images = np.array([self._transform(filename['image']) for filename in self.files])\n",
    "        self.__channels = False\n",
    " \n",
    "        # 扫描files字典中所有annotation 图片全路径\n",
    "        # 根据文件全路径读取图像，并将其扩充为三通道格式\n",
    "        self.annotations = np.array(\n",
    "            [np.expand_dims(self._transform(filename['annotation']), axis=3) for filename in self.files])\n",
    "        print (self.images.shape)\n",
    "        print (self.annotations.shape)\n",
    " \n",
    "    def _transform(self, filename):\n",
    "        # 读取文件图片\n",
    "        image = misc.imread(filename)\n",
    "        if self.__channels and len(image.shape) < 3:  # make sure images are of shape(h,w,3)\n",
    "            # 将图片三个通道设置为一样的图片\n",
    "            image = np.array([image for i in range(3)])\n",
    " \n",
    "        if self.image_options.get(\"resize\", False) and self.image_options[\"resize\"]:\n",
    " \n",
    "            resize_size = int(self.image_options[\"resize_size\"])\n",
    "            # 使用最近邻插值法resize图片\n",
    "            resize_image = misc.imresize(image,\n",
    "                                         [resize_size, resize_size], interp='nearest')\n",
    "        else:\n",
    "            resize_image = image\n",
    " \n",
    "        return np.array(resize_image)       # 返回已经resize的图片\n",
    " \n",
    "    def get_records(self):\n",
    "        \"\"\"\n",
    "        返回图片和标签全路径\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        return self.images, self.annotations\n",
    " \n",
    "    def reset_batch_offset(self, offset=0):\n",
    "        \"\"\"\n",
    "        剩下的batch\n",
    "        :param offset:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.batch_offset = offset\n",
    " \n",
    "    def next_batch(self, batch_size):\n",
    "        # 当前第几个batch\n",
    "        start = self.batch_offset\n",
    "        # 读取下一个batch  所有offset偏移量+batch_size\n",
    "        self.batch_offset += batch_size\n",
    "        # iamges存储所有图片信息 images.shape(len, h, w)\n",
    "        if self.batch_offset > self.images.shape[0]:      # 如果下一个batch的偏移量超过了图片总数 说明完成了一个epoch\n",
    "            # Finished epoch\n",
    "            self.epochs_completed += 1      # epochs完成总数+1\n",
    "            print(\"****************** Epochs completed: \" + str(self.epochs_completed) + \"******************\")\n",
    "            # Shuffle the data\n",
    "            perm = np.arange(self.images.shape[0])      # arange生成数组(0 - len-1) 获取图片索引\n",
    "            np.random.shuffle(perm)         # 对图片索引洗牌\n",
    "            self.images = self.images[perm]     # 洗牌之后的图片顺序\n",
    "            self.annotations = self.annotations[perm]\n",
    "            # Start next epoch\n",
    "            start = 0           # 下一个epoch从0开始\n",
    "            self.batch_offset = batch_size  # 已完成的batch偏移量\n",
    " \n",
    "        end = self.batch_offset             # 开始到结束self.batch_offset   self.batch_offset+batch_size\n",
    "        return self.images[start:end], self.annotations[start:end]      # 取出batch\n",
    " \n",
    "    def get_random_batch(self, batch_size):\n",
    "        # 按照一个batch_size一个块  进行对所有图片总数进行随机操作， 相当于洗牌工作\n",
    "        indexes = np.random.randint(0, self.images.shape[0], size=[batch_size]).tolist()\n",
    "        return self.images[indexes], self.annotations[indexes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load read_MITSceneParsingData.py\n",
    "__author__ = 'charlie'\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from six.moves import cPickle as pickle\n",
    "from tensorflow.python.platform import gfile\n",
    "import glob\n",
    " \n",
    "#import TensorflowUtils as utils\n",
    " \n",
    "# DATA_URL = 'http://sceneparsing.csail.mit.edu/data/ADEChallengeData2016.zip'\n",
    "DATA_URL = 'http://data.csail.mit.edu/places/ADEchallenge/ADEChallengeData2016.zip'\n",
    "\n",
    "\n",
    "def read_dataset(data_dir):\n",
    "    # data_dir = Data_zoo / MIT_SceneParsing /\n",
    "    pickle_filename = \"MITSceneParsing.pickle\"\n",
    "    # 文件路径  Data_zoo / MIT_SceneParsing / MITSceneParsing.pickle\n",
    "    pickle_filepath = os.path.join(data_dir, pickle_filename)\n",
    "    if not os.path.exists(pickle_filepath):\n",
    "        maybe_download_and_extract(data_dir, DATA_URL, is_zipfile=True)       # 不存在文件 则下载\n",
    "        SceneParsing_folder = os.path.splitext(DATA_URL.split(\"/\")[-1])[0]          # ADEChallengeData2016\n",
    "        # result =   {training: [{image: 图片全路径， annotation:标签全路径， filename:图片名字}] [][]\n",
    "        #            validation:[{image:图片全路径， annotation:标签全路径， filename:图片名字}] [] []}\n",
    "        result = create_image_lists(os.path.join(data_dir, SceneParsing_folder))    # Data_zoo / MIT_SceneParsing / ADEChallengeData2016\n",
    "        print (\"Pickling ...\")      # 制作pickle文件\n",
    "        with open(pickle_filepath, 'wb') as f:\n",
    "            pickle.dump(result, f, pickle.HIGHEST_PROTOCOL)\n",
    "    else:\n",
    "        print (\"Found pickle file!\")\n",
    " \n",
    "    with open(pickle_filepath, 'rb') as f:      # 打开pickle文件\n",
    "        result = pickle.load(f)                 # 读取\n",
    "        training_records = result['training']\n",
    "        validation_records = result['validation']\n",
    "        del result\n",
    "    # training: [{image: 图片全路径， annotation:标签全路径， filename:图片名字}] [{}][{}]\n",
    "    return training_records, validation_records\n",
    " \n",
    "    \n",
    "def create_image_lists(image_dir):\n",
    "    \"\"\"\n",
    "    :param image_dir:   Data_zoo / MIT_SceneParsing / ADEChallengeData2016\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if not gfile.Exists(image_dir):\n",
    "        print(\"Image directory '\" + image_dir + \"' not found.\")\n",
    "        return None\n",
    "    directories = ['training', 'validation']\n",
    "    image_list = {}     # 图像字典   training:[]  validation:[]\n",
    " \n",
    "    for directory in directories:       # 训练集和验证集 分别制作\n",
    "        file_list = []\n",
    "        image_list[directory] = []\n",
    "        # Data_zoo/MIT_SceneParsing/ADEChallengeData2016/images/training/*.jpg\n",
    "        file_glob = os.path.join(image_dir, \"images\", directory, '*.' + 'jpg')\n",
    "        # 加入文件列表  包含所有图片文件全路径+文件名字  如 Data_zoo/MIT_SceneParsing/ADEChallengeData2016/images/training/hi.jpg\n",
    "        file_list.extend(glob.glob(file_glob))\n",
    " \n",
    "        if not file_list:   # 文件为空\n",
    "            print('No files found')\n",
    "        else:\n",
    "            for f in file_list:     # 扫描文件列表   这里f对应文件全路径\n",
    "                # 获取图片名字 hi\n",
    "                filename = os.path.splitext(f.split(\"/\")[-1])[0]\n",
    "                # Data_zoo/MIT_SceneParsing/ADEChallengeData2016/annotations/training/*.png\n",
    "                annotation_file = os.path.join(image_dir, \"annotations\", directory, filename + '.png')\n",
    "                if os.path.exists(annotation_file):     # 如果文件路径存在\n",
    "                    #  image:图片全路径， annotation:标签全路径， filename:图片名字\n",
    "                    record = {'image': f, 'annotation': annotation_file, 'filename': filename}\n",
    "                    # image_list{training:[{image:图片全路径， annotation:标签全路径， filename:图片名字}] [] []\n",
    "                    #            validation:[{image:图片全路径， annotation:标签全路径， filename:图片名字}] [] []}\n",
    "                    image_list[directory].append(record)\n",
    "                else:\n",
    "                    print(\"Annotation file not found for %s - Skipping\" % filename)\n",
    "        # 对图片列表进行洗牌\n",
    "        random.shuffle(image_list[directory])\n",
    "        no_of_images = len(image_list[directory])   # 包含图片文件的个数\n",
    "        print ('No. of %s files: %d' % (directory, no_of_images))\n",
    " \n",
    "    return image_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    " \n",
    "#import TensorflowUtils as utils\n",
    "#import read_MITSceneParsingData as scene_parsing\n",
    "import datetime\n",
    "#import BatchDatsetReader as dataset\n",
    "from six.moves import xrange\n",
    " \n",
    "# 参数设置\n",
    "FLAGS = tf.flags.FLAGS\n",
    "tf.flags.DEFINE_integer(\"batch_size\", \"2\", \"batch size for training\")\n",
    "tf.flags.DEFINE_string(\"logs_dir\", \"logs/\", \"path to logs directory\")\n",
    "tf.flags.DEFINE_string(\"data_dir\", \"Data_zoo/MIT_SceneParsing/\", \"path to dataset\")\n",
    "tf.flags.DEFINE_float(\"learning_rate\", \"1e-6\", \"Learning rate for Adam Optimizer\")\n",
    "tf.flags.DEFINE_string(\"model_dir\", \"Model_zoo/\", \"Path to vgg model mat\")\n",
    "tf.flags.DEFINE_bool('debug', \"True\", \"Debug mode: True/ False\")\n",
    "tf.flags.DEFINE_string('mode', \"train\", \"Mode train/ test/ visualize\")\n",
    " \n",
    "MODEL_URL = 'http://www.vlfeat.org/matconvnet/models/beta16/imagenet-vgg-verydeep-19.mat'\n",
    " \n",
    "MAX_ITERATION = 200        # 迭代次数\n",
    "NUM_OF_CLASSESS = 151                # 类别数 151\n",
    "IMAGE_SIZE = 224                    # 图片大小 224\n",
    "fine_tuning = False\n",
    " \n",
    "# VGG网络部分，weights是权重集合， image是预测图像的向量\n",
    "def vgg_net(weights, image):\n",
    "    # VGG网络前五大部分\n",
    "    layers = (\n",
    "        'conv1_1', 'relu1_1', 'conv1_2', 'relu1_2', 'pool1',\n",
    " \n",
    "        'conv2_1', 'relu2_1', 'conv2_2', 'relu2_2', 'pool2',\n",
    " \n",
    "        'conv3_1', 'relu3_1', 'conv3_2', 'relu3_2', 'conv3_3',\n",
    "        'relu3_3', 'conv3_4', 'relu3_4', 'pool3',\n",
    " \n",
    "        'conv4_1', 'relu4_1', 'conv4_2', 'relu4_2', 'conv4_3',\n",
    "        'relu4_3', 'conv4_4', 'relu4_4', 'pool4',\n",
    " \n",
    "        'conv5_1', 'relu5_1', 'conv5_2', 'relu5_2', 'conv5_3',\n",
    "        'relu5_3', 'conv5_4', 'relu5_4'\n",
    "    )\n",
    " \n",
    "    net = {}\n",
    "    current = image     # 预测图像\n",
    "    for i, name in enumerate(layers):\n",
    "        kind = name[:4]\n",
    "        if kind == 'conv':\n",
    "            kernels, bias = weights[i][0][0][0][0]\n",
    "            # matconvnet: weights are [width, height, in_channels, out_channels]\n",
    "            # tensorflow: weights are [height, width, in_channels, out_channels]\n",
    "            kernels = get_variable(np.transpose(kernels, (1, 0, 2, 3)), name=name + \"_w\")     # conv1_1_w\n",
    "            bias = get_variable(bias.reshape(-1), name=name + \"_b\")       # conv1_1_b\n",
    "            current = conv2d_basic(current, kernels, bias)        # 前向传播结果 current\n",
    "        elif kind == 'relu':\n",
    "            current = tf.nn.relu(current, name=name)    # relu1_1\n",
    "            if FLAGS.debug:     # 是否开启debug模式 true / false\n",
    "                add_activation_summary(current)       # 画图\n",
    "        elif kind == 'pool':\n",
    "            # vgg 的前5层的stride都是2，也就是前5层的size依次减小1倍\n",
    "            # 这里处理了前4层的stride，用的是平均池化\n",
    "            # 第5层的pool在下文的外部处理了，用的是最大池化\n",
    "            # pool1 size缩小2倍\n",
    "            # pool2 size缩小4倍\n",
    "            # pool3 size缩小8倍\n",
    "            # pool4 size缩小16倍\n",
    "            current = avg_pool_2x2(current)\n",
    "        net[name] = current     # 每层前向传播结果放在net中， 是一个字典\n",
    " \n",
    "    return net\n",
    " \n",
    "\n",
    "# 预测流程，image是输入图像，keep_prob dropout比例\n",
    "def inference(image, keep_prob):\n",
    "    \"\"\"\n",
    "    Semantic segmentation network definition    # 语义分割网络定义\n",
    "    :param image: input image. Should have values in range 0-255\n",
    "    :param keep_prob:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # 获取预训练网络VGG\n",
    "    print(\"setting up vgg initialized conv layers ...\")\n",
    "    # model_dir Model_zoo/\n",
    "    # MODEL_URL 下载VGG19网址\n",
    "    model_data = get_model_data(FLAGS.model_dir, MODEL_URL)       # 返回VGG19模型中内容\n",
    " \n",
    "    mean = model_data['normalization'][0][0][0]                         # 获得图像均值\n",
    "    mean_pixel = np.mean(mean, axis=(0, 1))                             # RGB\n",
    " \n",
    "    weights = np.squeeze(model_data['layers'])                          # 压缩VGG网络中参数，把维度是1的维度去掉 剩下的就是权重\n",
    " \n",
    "    processed_image = process_image(image, mean_pixel)            # 图像减均值\n",
    " \n",
    "    with tf.variable_scope(\"inference\"):                                # 命名作用域 是inference\n",
    "        image_net = vgg_net(weights, processed_image)                   # 传入权重参数和预测图像，获得所有层输出结果\n",
    "        conv_final_layer = image_net[\"conv5_3\"]                         # 获得输出结果\n",
    " \n",
    "        pool5 = max_pool_2x2(conv_final_layer)                    # /32 缩小32倍\n",
    " \n",
    "        W6 = weight_variable([7, 7, 512, 4096], name=\"W6\")        # 初始化第6层的w b\n",
    "        b6 = bias_variable([4096], name=\"b6\")\n",
    "        conv6 = conv2d_basic(pool5, W6, b6)\n",
    "        relu6 = tf.nn.relu(conv6, name=\"relu6\")\n",
    "        if FLAGS.debug:\n",
    "            add_activation_summary(relu6)\n",
    "        relu_dropout6 = tf.nn.dropout(relu6, keep_prob=keep_prob)\n",
    " \n",
    "        W7 = weight_variable([1, 1, 4096, 4096], name=\"W7\")       # 第7层卷积层\n",
    "        b7 = bias_variable([4096], name=\"b7\")\n",
    "        conv7 = conv2d_basic(relu_dropout6, W7, b7)\n",
    "        relu7 = tf.nn.relu(conv7, name=\"relu7\")\n",
    "        if FLAGS.debug:\n",
    "            add_activation_summary(relu7)\n",
    "        relu_dropout7 = tf.nn.dropout(relu7, keep_prob=keep_prob)\n",
    " \n",
    "        W8 = weight_variable([1, 1, 4096, NUM_OF_CLASSESS], name=\"W8\")\n",
    "        b8 = bias_variable([NUM_OF_CLASSESS], name=\"b8\")\n",
    "        conv8 = conv2d_basic(relu_dropout7, W8, b8)               # 第8层卷积层 分类151类\n",
    "        # annotation_pred1 = tf.argmax(conv8, dimension=3, name=\"prediction1\")\n",
    " \n",
    "        # now to upscale to actual image size\n",
    "        deconv_shape1 = image_net[\"pool4\"].get_shape()                  # 将pool4 1/16结果尺寸拿出来 做融合 [b,h,w,c]\n",
    "        # 定义反卷积层的 W，B [H, W, OUTC, INC]  输出个数为pool4层通道个数，输入为conv8通道个数\n",
    "        # 扩大两倍  所以stride = 2  kernel_size = 4\n",
    "        W_t1 = weight_variable([4, 4, deconv_shape1[3].value, NUM_OF_CLASSESS], name=\"W_t1\")\n",
    "        b_t1 = bias_variable([deconv_shape1[3].value], name=\"b_t1\")\n",
    "        # 输入为conv8特征图，使得其特征图大小扩大两倍，并且特征图个数变为pool4的通道数\n",
    "        conv_t1 = conv2d_transpose_strided(conv8, W_t1, b_t1, output_shape=tf.shape(image_net[\"pool4\"]))\n",
    "        fuse_1 = tf.add(conv_t1, image_net[\"pool4\"], name=\"fuse_1\")     # 进行融合 逐像素相加\n",
    " \n",
    "        # 获得pool3尺寸 是原图大小的1/8\n",
    "        deconv_shape2 = image_net[\"pool3\"].get_shape()\n",
    "        # 输出通道数为pool3通道数，  输入通道数为pool4通道数\n",
    "        W_t2 = weight_variable([4, 4, deconv_shape2[3].value, deconv_shape1[3].value], name=\"W_t2\")\n",
    "        b_t2 = bias_variable([deconv_shape2[3].value], name=\"b_t2\")\n",
    "        # 将上一层融合结果fuse_1在扩大两倍，输出尺寸和pool3相同\n",
    "        conv_t2 = conv2d_transpose_strided(fuse_1, W_t2, b_t2, output_shape=tf.shape(image_net[\"pool3\"]))\n",
    "        # 融合操作deconv(fuse_1) + pool3\n",
    "        fuse_2 = tf.add(conv_t2, image_net[\"pool3\"], name=\"fuse_2\")\n",
    " \n",
    "        shape = tf.shape(image)     # 获得原始图像大小\n",
    "        # 堆叠列表，反卷积输出尺寸，[b，原图H，原图W，类别个数]\n",
    "        deconv_shape3 = tf.stack([shape[0], shape[1], shape[2], NUM_OF_CLASSESS])\n",
    "        # 建立反卷积w[8倍扩大需要ks=16, 输出通道数为类别个数， 输入通道数pool3通道数]\n",
    "        W_t3 = weight_variable([16, 16, NUM_OF_CLASSESS, deconv_shape2[3].value], name=\"W_t3\")\n",
    "        b_t3 = bias_variable([NUM_OF_CLASSESS], name=\"b_t3\")\n",
    "        # 反卷积，fuse_2反卷积，输出尺寸为 [b，原图H，原图W，类别个数]\n",
    "        conv_t3 = conv2d_transpose_strided(fuse_2, W_t3, b_t3, output_shape=deconv_shape3, stride=8)\n",
    " \n",
    "        # 目前conv_t3的形式为size为和原始图像相同的size，通道数与分类数相同\n",
    "        # 这句我的理解是对于每个像素位置，根据第3维度（通道数）通过argmax能计算出这个像素点属于哪个分类\n",
    "        # 也就是对于每个像素而言，NUM_OF_CLASSESS个通道中哪个数值最大，这个像素就属于哪个分类\n",
    "        # 每个像素点有21个值，哪个值最大就属于那一类\n",
    "        # 返回一张图，每一个点对于其来别信息shape=[b,h,w]\n",
    "        annotation_pred = tf.argmax(conv_t3, dimension=3, name=\"prediction\")\n",
    "    # 从第三维度扩展 形成[b,h,w,c] 其中c=1, conv_t3最后具有21深度的特征图\n",
    "    return tf.expand_dims(annotation_pred, dim=3), conv_t3\n",
    " \n",
    " \n",
    " \n",
    "def train(loss_val, var_list):\n",
    "    \"\"\"\n",
    "    :param loss_val:  损失函数\n",
    "    :param var_list:  需要优化的值\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    optimizer = tf.train.AdamOptimizer(FLAGS.learning_rate)\n",
    "    grads = optimizer.compute_gradients(loss_val, var_list=var_list)\n",
    "    if FLAGS.debug:\n",
    "        # print(len(var_list))\n",
    "        for grad, var in grads:\n",
    "            add_gradient_summary(grad, var)\n",
    "    return optimizer.apply_gradients(grads)     # 返回迭代梯度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv=None):\n",
    "    # dropout保留率\n",
    "    keep_probability = tf.placeholder(tf.float32, name=\"keep_probabilty\")\n",
    "    # 图像占坑\n",
    "    image = tf.placeholder(tf.float32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 3], name=\"input_image\")\n",
    "    # 标签占坑\n",
    "    annotation = tf.placeholder(tf.int32, shape=[None, IMAGE_SIZE, IMAGE_SIZE, 1], name=\"annotation\")\n",
    " \n",
    "    # 预测一个batch图像  获得预测图[b,h,w,c=1]  结果特征图[b,h,w,c=151]\n",
    "    pred_annotation, logits = inference(image, keep_probability)\n",
    "    tf.summary.image(\"input_image\", image, max_outputs=2)\n",
    "    tf.summary.image(\"ground_truth\", tf.cast(annotation, tf.uint8), max_outputs=2)\n",
    "    tf.summary.image(\"pred_annotation\", tf.cast(pred_annotation, tf.uint8), max_outputs=2)\n",
    "    # 空间交叉熵损失函数[b,h,w,c=151]  和labels[b,h,w]    每一张图分别对比\n",
    "    loss = tf.reduce_mean((tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits,\n",
    "                                                                          labels=tf.squeeze(annotation, squeeze_dims=[3]),\n",
    "                                                                          name=\"entropy\")))\n",
    "    tf.summary.scalar(\"entropy\", loss)\n",
    " \n",
    "    # 返回需要训练的变量列表\n",
    "    trainable_var = tf.trainable_variables()\n",
    "    if FLAGS.debug:\n",
    "        for var in trainable_var:\n",
    "            add_to_regularization_and_summary(var)\n",
    " \n",
    "    # 传入损失函数和需要训练的变量列表\n",
    "    train_op = train(loss, trainable_var)\n",
    " \n",
    "    print(\"Setting up summary op...\")\n",
    "    # 生成绘图数据\n",
    "    summary_op = tf.summary.merge_all()\n",
    " \n",
    "    print(\"Setting up image reader...\")\n",
    "    # data_dir = Data_zoo/MIT_SceneParsing/\n",
    "    # training: [{image: 图片全路径， annotation:标签全路径， filename:图片名字}] [{}][{}]\n",
    "    train_records, valid_records = read_dataset(FLAGS.data_dir)\n",
    "    print(len(train_records))   # 长度\n",
    "    print(len(valid_records))\n",
    " \n",
    "    print(\"Setting up dataset reader\")\n",
    "    image_options = {'resize': True, 'resize_size': IMAGE_SIZE}\n",
    "    if FLAGS.mode == 'train':\n",
    "        # 读取图片 产生类对象 其中包含所有图片信息\n",
    "        train_dataset_reader = BatchDatset(train_records, image_options)\n",
    "    validation_dataset_reader = BatchDatset(valid_records, image_options)\n",
    " \n",
    "    sess = tf.Session()\n",
    " \n",
    "    print(\"Setting up Saver...\")\n",
    "    saver = tf.train.Saver()\n",
    "    summary_writer = tf.summary.FileWriter(FLAGS.logs_dir, sess.graph)\n",
    " \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    #sess = tf_debug.TensorBoardDebugWrapperSession(sess, 'localhost:6064')\n",
    "    \n",
    "    # logs/\n",
    "    if fine_tuning:\n",
    "        ckpt = tf.train.get_checkpoint_state(FLAGS.logs_dir)    # 训练断点回复\n",
    "        if ckpt and ckpt.model_checkpoint_path:                 # 如果存在checkpoint文件 则恢复sess\n",
    "            saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            print(\"Model restored...\")\n",
    " \n",
    "    if FLAGS.mode == \"train\":\n",
    "        for itr in range(MAX_ITERATION):\n",
    "            # 读取下一batch\n",
    "            train_images, train_annotations = train_dataset_reader.next_batch(FLAGS.batch_size)\n",
    "            feed_dict = {image: train_images, annotation: train_annotations, keep_probability: 0.85}\n",
    " \n",
    "            # 迭代优化需要训练的变量\n",
    "            sess.run(train_op, feed_dict=feed_dict)\n",
    " \n",
    "            if itr % 10 == 0:\n",
    "                # 迭代10次打印显示\n",
    "                train_loss, summary_str = sess.run([loss, summary_op], feed_dict=feed_dict)\n",
    "                print(\"Step: %d, Train_loss:%g\" % (itr, train_loss))\n",
    "                summary_writer.add_summary(summary_str, itr)\n",
    " \n",
    "            if itr % 500 == 0:\n",
    "                # 迭代500 次验证\n",
    "                valid_images, valid_annotations = validation_dataset_reader.next_batch(FLAGS.batch_size)\n",
    "                valid_loss = sess.run(loss, feed_dict={image: valid_images, annotation: valid_annotations,\n",
    "                                                       keep_probability: 1.0})\n",
    "                print(\"%s ---> Validation_loss: %g\" % (datetime.datetime.now(), valid_loss))\n",
    "                # 保存模型\n",
    "                saver.save(sess, FLAGS.logs_dir + \"model.ckpt\", itr)\n",
    " \n",
    "    elif FLAGS.mode == \"visualize\":\n",
    "        # 可视化\n",
    "        valid_images, valid_annotations = validation_dataset_reader.get_random_batch(FLAGS.batch_size)\n",
    "        # pred_annotation预测结果图\n",
    "        pred = sess.run(pred_annotation, feed_dict={image: valid_images, annotation: valid_annotations,\n",
    "                                                    keep_probability: 1.0})\n",
    "        valid_annotations = np.squeeze(valid_annotations, axis=3)\n",
    "        pred = np.squeeze(pred, axis=3)\n",
    " \n",
    "        for itr in range(FLAGS.batch_size):\n",
    "            save_image(valid_images[itr].astype(np.uint8), FLAGS.logs_dir, name=\"inp_\" + str(5+itr))\n",
    "            save_image(valid_annotations[itr].astype(np.uint8), FLAGS.logs_dir, name=\"gt_\" + str(5+itr))\n",
    "            save_image(pred[itr].astype(np.uint8), FLAGS.logs_dir, name=\"pred_\" + str(5+itr))\n",
    "            print(\"Saved image: %d\" % itr)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
